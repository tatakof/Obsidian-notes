https://utkusen.com/blog/generating-personalized-wordlists

https://github.com/franfram/password-similarity-nlp








**Overall, subword tokenization provides a way to easily scale between character tokenization (i.e., using a small subword vocab) and word tokenization (i.e., using a large subword vocab), and handles every human language without needing language-specific algorithms to be developed. It can even handle other "languages" such as genomic sequences or MIDI music notation!** 




