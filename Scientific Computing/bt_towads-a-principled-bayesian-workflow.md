from blogpost 'Towards a Principled Bayesian Workflow'


https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html

Given a probabilistic model and a realized observation, bayesian inference is straightforward to implement. At least conceptually. Inferences, and any decisions based upon them, follow immediately in the form of expectations with respect to the induced posterior distribution. Building a probabilistic model that is useful in a given application, however, is a far more open-ended challenge. 

I personally use 'principled' to refer to choices informed by sincere and careful deliberation, in contrast to choices informed by unquestioned defaults that have ossified into convention. A principled workflow considers whether or not modeling assumptions are appropriate and sufficient for answering relevant questions in your particular applied context. Because everyone asks different questions in different contexts, such a workflow cannot be reduced to a deterministic algorithm. All we can do is assemble a coherent set of techniques to help us evaluate our own assumptions and guide our unique path through model space. 

Most of the key concepts in my recommenden workflow can be found in the visionary work of statisticians like george box and i.j. Good... That said, the specific workflow that i advocate here is only my perspective, and one that is focused on the needs of modeling and inference in applications where the data are rich and structured. It does not necessarily reflect the perspectives taken by other researchers working in model evaluation and development, and it may indeed prove to be limiting in other circumstances. 

Moreover, as this workflow is an active topic of research by myself and others it is subject to evolution and refinement. 


Need to read modeling and inference case study first...

